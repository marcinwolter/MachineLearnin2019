{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression_keras_aboleth.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/MachineLearnin2019/blob/master/regression_keras_aboleth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipxTAQQ0jOoy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d27ac80-6db4-445b-d549-e4b7de96db76"
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "\"\"\"This is a demonstration of how to use Keras with Aboleth.\"\"\"\n",
        "\n",
        "!pip install aboleth\n",
        "\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import bokeh.plotting as bk\n",
        "import bokeh.palettes as bp\n",
        "\n",
        "# from sklearn.gaussian_process.kernels import Matern as kern\n",
        "from sklearn.gaussian_process.kernels import RBF as kern\n",
        "\n",
        "import aboleth as ab\n",
        "from aboleth.datasets import gp_draws\n",
        "from aboleth.layers import SampleLayer\n",
        "\n",
        "\n",
        "# Set up a python logger so we can see the output of MonitoredTrainingSession\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Set up a consistent random seed in Aboleth so we get repeatable, but random\n",
        "# results\n",
        "RSEED = 666\n",
        "ab.set_hyperseed(RSEED)\n",
        "\n",
        "# Data settings\n",
        "N = 1000  # Number of training points to generate\n",
        "Ns = 400  # Number of testing points to generate\n",
        "kernel = kern(length_scale=1.5)  # Kernel to use for making a random GP draw\n",
        "true_noise = 0.1  # Add noise to the GP draws, to make things a little harder\n",
        "\n",
        "# Model settings\n",
        "n_samples = 5  # Number of random samples to get from an Aboleth net\n",
        "p_samples = 50  # Number of samples for prediction\n",
        "n_epochs = 500  # how many times to see the data for training\n",
        "batch_size = 10  # mini batch size for stochastric gradients\n",
        "config = tf.ConfigProto(device_count={'GPU': 0})  # Use GPU? 0 is no\n",
        "\n",
        "# Model initialisation\n",
        "NOISE = 1.\n",
        "\n",
        "\n",
        "class WrapperLayer(SampleLayer):\n",
        "\n",
        "    def __init__(self, layer, *args, **kwargs):\n",
        "        self.layer = layer(*args, **kwargs)\n",
        "\n",
        "    def _build(self, X):\n",
        "        \"\"\"Build the graph of this layer.\"\"\"\n",
        "        Net = self.layer(X)\n",
        "        # aggregate layer regularization terms\n",
        "        KL = tf.reduce_sum(self.layer.losses)\n",
        "\n",
        "        return Net, KL\n",
        "\n",
        "\n",
        "n_samples_ = tf.placeholder(tf.int32)\n",
        "\n",
        "l1_l2_reg = tf.keras.regularizers.l1_l2(l1=0., l2=0.)\n",
        "net = (\n",
        "   ab.InputLayer(name=\"X\", n_samples=n_samples_) >>\n",
        "   WrapperLayer(tf.keras.layers.Dense, units=64, activation='tanh',\n",
        "                kernel_regularizer=l1_l2_reg, bias_regularizer=l1_l2_reg) >>\n",
        "   ab.DropOut(keep_prob=.9) >>\n",
        "   WrapperLayer(tf.keras.layers.Dense, units=32, activation='tanh',\n",
        "                kernel_regularizer=l1_l2_reg, bias_regularizer=l1_l2_reg) >>\n",
        "   ab.DropOut(keep_prob=.9) >>\n",
        "   WrapperLayer(tf.keras.layers.Dense, units=1, kernel_regularizer=l1_l2_reg,\n",
        "                bias_regularizer=l1_l2_reg)\n",
        ")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run the demo.\"\"\"\n",
        "    n_iters = int(round(n_epochs * N / batch_size))\n",
        "    print(\"Iterations = {}\".format(n_iters))\n",
        "\n",
        "    # Get training and testing data\n",
        "    Xr, Yr, Xs, Ys = gp_draws(N, Ns, kern=kernel, noise=true_noise)\n",
        "\n",
        "    # Prediction points\n",
        "    Xq = np.linspace(-20, 20, Ns).astype(np.float32)[:, np.newaxis]\n",
        "    Yq = np.linspace(-4, 4, Ns).astype(np.float32)[:, np.newaxis]\n",
        "\n",
        "    # Set up the probability image query points\n",
        "    Xi, Yi = np.meshgrid(Xq, Yq)\n",
        "    Xi = Xi.astype(np.float32).reshape(-1, 1)\n",
        "    Yi = Yi.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "    _, D = Xr.shape\n",
        "\n",
        "    # Name the \"data\" parts of the graph\n",
        "    with tf.name_scope(\"Input\"):\n",
        "        # This function will make a TensorFlow queue for shuffling and batching\n",
        "        # the data, and will run through n_epochs of the data.\n",
        "        Xb, Yb = batch_training(Xr, Yr, n_epochs=n_epochs,\n",
        "                                batch_size=batch_size)\n",
        "        X_ = tf.placeholder_with_default(Xb, shape=(None, D))\n",
        "        Y_ = tf.placeholder_with_default(Yb, shape=(None, 1))\n",
        "\n",
        "    # This is where we build the actual GP model\n",
        "    with tf.name_scope(\"Deepnet\"):\n",
        "        phi, reg = net(X=X_)\n",
        "        noise = ab.pos_variable(NOISE)\n",
        "        ll = tf.distributions.Normal(loc=phi, scale=noise).log_prob(Y_)\n",
        "        loss = ab.max_posterior(ll, reg)\n",
        "\n",
        "    # Set up the trainig graph\n",
        "    with tf.name_scope(\"Train\"):\n",
        "        optimizer = tf.train.AdamOptimizer()\n",
        "        global_step = tf.train.create_global_step()\n",
        "        train = optimizer.minimize(loss, global_step=global_step)\n",
        "\n",
        "    # This is used for building the predictive density image\n",
        "    with tf.name_scope(\"Predict\"):\n",
        "        logprob = tf.reduce_mean(ll, axis=0)\n",
        "\n",
        "    # Logging learning progress\n",
        "    log = tf.train.LoggingTensorHook(\n",
        "        {'step': global_step, 'loss': loss},\n",
        "        every_n_iter=1000\n",
        "    )\n",
        "\n",
        "    # This is the main training \"loop\"\n",
        "    with tf.train.MonitoredTrainingSession(\n",
        "            config=config,\n",
        "            save_summaries_steps=None,\n",
        "            save_checkpoint_secs=None,\n",
        "            hooks=[log]\n",
        "    ) as sess:\n",
        "        try:\n",
        "            while not sess.should_stop():\n",
        "                sess.run(train, feed_dict={\n",
        "                            n_samples_: n_samples,\n",
        "                            # tf.keras.backend.learning_phase(): 1\n",
        "                         })\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            print('Input queues have been exhausted!')\n",
        "            pass\n",
        "\n",
        "        # Prediction, the [[None]] is to stop the default placeholder queue\n",
        "        # we keep learning phase flag on even in prediction phase to draw\n",
        "        # samples from predictive distribution\n",
        "        Ey = sess.run(phi,\n",
        "                      feed_dict={X_: Xq, Y_: [[None]], n_samples_: p_samples})\n",
        "\n",
        "        logPY = sess.run(logprob,\n",
        "                         feed_dict={Y_: Yi, X_: Xi, n_samples_: p_samples})\n",
        "\n",
        "    Eymean = Ey.mean(axis=0)  # Average samples to get mean predicted funtion\n",
        "    Py = np.exp(logPY.reshape(Ns, Ns))  # Turn log-prob into prob\n",
        "\n",
        "    # Plot\n",
        "    im_min = np.amin(Py)\n",
        "    im_size = np.amax(Py) - im_min\n",
        "    img = (Py - im_min) / im_size\n",
        "    f = bk.figure(tools='pan,box_zoom,reset', sizing_mode='stretch_both')\n",
        "    f.image(image=[img], x=-20., y=-4., dw=40., dh=8,\n",
        "            palette=bp.Plasma256)\n",
        "    f.circle(Xr.flatten(), Yr.flatten(), fill_color='blue', legend='Training')\n",
        "    f.line(Xs.flatten(), Ys.flatten(), line_color='blue', legend='Truth')\n",
        "    for y in Ey:\n",
        "        f.line(Xq.flatten(), y.flatten(), line_color='red', legend='Samples',\n",
        "               alpha=0.2)\n",
        "    f.line(Xq.flatten(), Eymean.flatten(), line_color='green', legend='Mean')\n",
        "    bk.show(f)\n",
        "    bk.save(f,filename=\"plot.html\")\n",
        "    bk.show(f)\n",
        "\n",
        "\n",
        "def batch_training(X, Y, batch_size, n_epochs):\n",
        "    \"\"\"Batch training queue convenience function.\"\"\"\n",
        "    data_tr = tf.data.Dataset.from_tensor_slices({'X': X, 'Y': Y}) \\\n",
        "        .shuffle(buffer_size=1000, seed=RSEED) \\\n",
        "        .repeat(n_epochs) \\\n",
        "        .batch(batch_size)\n",
        "    data = data_tr.make_one_shot_iterator().get_next()\n",
        "    return data['X'], data['Y']\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aboleth in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: tensorflow>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from aboleth) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from aboleth) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from aboleth) (1.3.3)\n",
            "Requirement already satisfied: tensorflow-probability>=0.3 in /usr/local/lib/python3.6/dist-packages (from aboleth) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.1.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (3.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.17.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.15.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.3->aboleth) (4.4.1)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.3->aboleth) (1.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.10.0->aboleth) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.10.0->aboleth) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.10.0->aboleth) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.10.0->aboleth) (2.8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aboleth/distributions.py:157: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "Iterations = 50000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-1-c0683c472a8f>:178: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aboleth/layers.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aboleth/util.py:169: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-1-c0683c472a8f>:109: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:loss = 1.7774174, step = 1\n",
            "INFO:tensorflow:loss = 0.8777404, step = 1001 (1.039 sec)\n",
            "INFO:tensorflow:loss = 0.8831567, step = 2001 (0.939 sec)\n",
            "INFO:tensorflow:loss = 0.6244984, step = 3001 (0.942 sec)\n",
            "INFO:tensorflow:loss = 0.71918154, step = 4001 (0.929 sec)\n",
            "INFO:tensorflow:loss = 0.7138323, step = 5001 (0.953 sec)\n",
            "INFO:tensorflow:loss = 0.5798312, step = 6001 (0.946 sec)\n",
            "INFO:tensorflow:loss = 0.6443031, step = 7001 (0.949 sec)\n",
            "INFO:tensorflow:loss = 0.4668466, step = 8001 (0.946 sec)\n",
            "INFO:tensorflow:loss = 0.34518254, step = 9001 (0.962 sec)\n",
            "INFO:tensorflow:loss = 0.68233335, step = 10001 (0.932 sec)\n",
            "INFO:tensorflow:loss = 0.6501354, step = 11001 (0.926 sec)\n",
            "INFO:tensorflow:loss = 0.5363214, step = 12001 (0.947 sec)\n",
            "INFO:tensorflow:loss = 0.39524326, step = 13001 (0.948 sec)\n",
            "INFO:tensorflow:loss = 0.2725677, step = 14001 (0.950 sec)\n",
            "INFO:tensorflow:loss = 0.3878754, step = 15001 (0.947 sec)\n",
            "INFO:tensorflow:loss = 0.31461278, step = 16001 (0.948 sec)\n",
            "INFO:tensorflow:loss = 0.30004433, step = 17001 (0.955 sec)\n",
            "INFO:tensorflow:loss = 0.4028412, step = 18001 (1.000 sec)\n",
            "INFO:tensorflow:loss = 0.23381783, step = 19001 (0.968 sec)\n",
            "INFO:tensorflow:loss = 0.32640925, step = 20001 (1.011 sec)\n",
            "INFO:tensorflow:loss = 0.183573, step = 21001 (0.983 sec)\n",
            "INFO:tensorflow:loss = 0.20282203, step = 22001 (0.936 sec)\n",
            "INFO:tensorflow:loss = 0.17154641, step = 23001 (0.944 sec)\n",
            "INFO:tensorflow:loss = 0.10068334, step = 24001 (0.998 sec)\n",
            "INFO:tensorflow:loss = 0.14696929, step = 25001 (0.930 sec)\n",
            "INFO:tensorflow:loss = 0.3775383, step = 26001 (0.908 sec)\n",
            "INFO:tensorflow:loss = 0.1737577, step = 27001 (0.918 sec)\n",
            "INFO:tensorflow:loss = 0.21490864, step = 28001 (0.936 sec)\n",
            "INFO:tensorflow:loss = 0.4108282, step = 29001 (0.988 sec)\n",
            "INFO:tensorflow:loss = 0.106033824, step = 30001 (0.939 sec)\n",
            "INFO:tensorflow:loss = 0.28309005, step = 31001 (0.914 sec)\n",
            "INFO:tensorflow:loss = 0.23836096, step = 32001 (0.915 sec)\n",
            "INFO:tensorflow:loss = 0.07169372, step = 33001 (0.935 sec)\n",
            "INFO:tensorflow:loss = 0.28437862, step = 34001 (0.941 sec)\n",
            "INFO:tensorflow:loss = 0.14576416, step = 35001 (0.912 sec)\n",
            "INFO:tensorflow:loss = 0.118791774, step = 36001 (0.939 sec)\n",
            "INFO:tensorflow:loss = 0.116190195, step = 37001 (0.935 sec)\n",
            "INFO:tensorflow:loss = 0.35937604, step = 38001 (0.938 sec)\n",
            "INFO:tensorflow:loss = 0.20662048, step = 39001 (0.939 sec)\n",
            "INFO:tensorflow:loss = 0.38799897, step = 40001 (0.938 sec)\n",
            "INFO:tensorflow:loss = 0.16558151, step = 41001 (0.934 sec)\n",
            "INFO:tensorflow:loss = 0.3051197, step = 42001 (0.944 sec)\n",
            "INFO:tensorflow:loss = 0.31217164, step = 43001 (0.927 sec)\n",
            "INFO:tensorflow:loss = 0.38273114, step = 44001 (0.915 sec)\n",
            "INFO:tensorflow:loss = 0.044006146, step = 45001 (0.934 sec)\n",
            "INFO:tensorflow:loss = 0.1405856, step = 46001 (0.945 sec)\n",
            "INFO:tensorflow:loss = 0.026357243, step = 47001 (0.948 sec)\n",
            "INFO:tensorflow:loss = 0.20307465, step = 48001 (0.973 sec)\n",
            "INFO:tensorflow:loss = 0.12876806, step = 49001 (0.937 sec)\n",
            "Input queues have been exhausted!\n",
            "INFO:tensorflow:loss = nan, step = 50000 (1.001 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bokeh/io/saving.py:126: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
            "  warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
            "/usr/local/lib/python3.6/dist-packages/bokeh/io/saving.py:139: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
            "  warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}