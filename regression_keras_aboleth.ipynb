{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression_keras_aboleth.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/MachineLearnin2019/blob/master/regression_keras_aboleth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipxTAQQ0jOoy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1daa6e4f-b146-4e56-94d8-1eef4a320af4"
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "\"\"\"This is a demonstration of how to use Keras with Aboleth.\"\"\"\n",
        "\n",
        "!pip install aboleth\n",
        "\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import bokeh.plotting as bk\n",
        "import bokeh.palettes as bp\n",
        "\n",
        "# from sklearn.gaussian_process.kernels import Matern as kern\n",
        "from sklearn.gaussian_process.kernels import RBF as kern\n",
        "\n",
        "import aboleth as ab\n",
        "from aboleth.datasets import gp_draws\n",
        "from aboleth.layers import SampleLayer\n",
        "\n",
        "\n",
        "# Set up a python logger so we can see the output of MonitoredTrainingSession\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Set up a consistent random seed in Aboleth so we get repeatable, but random\n",
        "# results\n",
        "RSEED = 666\n",
        "ab.set_hyperseed(RSEED)\n",
        "\n",
        "# Data settings\n",
        "N = 1000  # Number of training points to generate\n",
        "Ns = 400  # Number of testing points to generate\n",
        "kernel = kern(length_scale=1.5)  # Kernel to use for making a random GP draw\n",
        "true_noise = 0.1  # Add noise to the GP draws, to make things a little harder\n",
        "\n",
        "# Model settings\n",
        "n_samples = 5  # Number of random samples to get from an Aboleth net\n",
        "p_samples = 50  # Number of samples for prediction\n",
        "n_epochs = 500  # how many times to see the data for training\n",
        "batch_size = 10  # mini batch size for stochastric gradients\n",
        "config = tf.ConfigProto(device_count={'GPU': 0})  # Use GPU? 0 is no\n",
        "\n",
        "# Model initialisation\n",
        "NOISE = 1.\n",
        "\n",
        "\n",
        "class WrapperLayer(SampleLayer):\n",
        "\n",
        "    def __init__(self, layer, *args, **kwargs):\n",
        "        self.layer = layer(*args, **kwargs)\n",
        "\n",
        "    def _build(self, X):\n",
        "        \"\"\"Build the graph of this layer.\"\"\"\n",
        "        Net = self.layer(X)\n",
        "        # aggregate layer regularization terms\n",
        "        KL = tf.reduce_sum(self.layer.losses)\n",
        "\n",
        "        return Net, KL\n",
        "\n",
        "\n",
        "n_samples_ = tf.placeholder(tf.int32)\n",
        "\n",
        "l1_l2_reg = tf.keras.regularizers.l1_l2(l1=0., l2=0.)\n",
        "net = (\n",
        "   ab.InputLayer(name=\"X\", n_samples=n_samples_) >>\n",
        "   WrapperLayer(tf.keras.layers.Dense, units=128, activation='tanh',\n",
        "                kernel_regularizer=l1_l2_reg, bias_regularizer=l1_l2_reg) >>\n",
        "   ab.DropOut(keep_prob=.9) >>\n",
        "   WrapperLayer(tf.keras.layers.Dense, units=64, activation='tanh',\n",
        "                kernel_regularizer=l1_l2_reg, bias_regularizer=l1_l2_reg) >>\n",
        "   ab.DropOut(keep_prob=.9) >>\n",
        "   WrapperLayer(tf.keras.layers.Dense, units=32, activation='tanh',\n",
        "                kernel_regularizer=l1_l2_reg, bias_regularizer=l1_l2_reg) >>\n",
        "   ab.DropOut(keep_prob=.9) >>\n",
        "   WrapperLayer(tf.keras.layers.Dense, units=1, kernel_regularizer=l1_l2_reg,\n",
        "                bias_regularizer=l1_l2_reg)\n",
        ")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run the demo.\"\"\"\n",
        "    n_iters = int(round(n_epochs * N / batch_size))\n",
        "    print(\"Iterations = {}\".format(n_iters))\n",
        "\n",
        "    # Get training and testing data\n",
        "    Xr, Yr, Xs, Ys = gp_draws(N, Ns, kern=kernel, noise=true_noise)\n",
        "\n",
        "    # Prediction points\n",
        "    Xq = np.linspace(-20, 20, Ns).astype(np.float32)[:, np.newaxis]\n",
        "    Yq = np.linspace(-4, 4, Ns).astype(np.float32)[:, np.newaxis]\n",
        "\n",
        "    # Set up the probability image query points\n",
        "    Xi, Yi = np.meshgrid(Xq, Yq)\n",
        "    Xi = Xi.astype(np.float32).reshape(-1, 1)\n",
        "    Yi = Yi.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "    _, D = Xr.shape\n",
        "\n",
        "    # Name the \"data\" parts of the graph\n",
        "    with tf.name_scope(\"Input\"):\n",
        "        # This function will make a TensorFlow queue for shuffling and batching\n",
        "        # the data, and will run through n_epochs of the data.\n",
        "        Xb, Yb = batch_training(Xr, Yr, n_epochs=n_epochs,\n",
        "                                batch_size=batch_size)\n",
        "        X_ = tf.placeholder_with_default(Xb, shape=(None, D))\n",
        "        Y_ = tf.placeholder_with_default(Yb, shape=(None, 1))\n",
        "\n",
        "    # This is where we build the actual GP model\n",
        "    with tf.name_scope(\"Deepnet\"):\n",
        "        phi, reg = net(X=X_)\n",
        "        noise = ab.pos_variable(NOISE)\n",
        "        ll = tf.distributions.Normal(loc=phi, scale=noise).log_prob(Y_)\n",
        "        loss = ab.max_posterior(ll, reg)\n",
        "\n",
        "    # Set up the trainig graph\n",
        "    with tf.name_scope(\"Train\"):\n",
        "        optimizer = tf.train.AdamOptimizer()\n",
        "        global_step = tf.train.create_global_step()\n",
        "        train = optimizer.minimize(loss, global_step=global_step)\n",
        "\n",
        "    # This is used for building the predictive density image\n",
        "    with tf.name_scope(\"Predict\"):\n",
        "        logprob = tf.reduce_mean(ll, axis=0)\n",
        "\n",
        "    # Logging learning progress\n",
        "    log = tf.train.LoggingTensorHook(\n",
        "        {'step': global_step, 'loss': loss},\n",
        "        every_n_iter=1000\n",
        "    )\n",
        "\n",
        "    # This is the main training \"loop\"\n",
        "    with tf.train.MonitoredTrainingSession(\n",
        "            config=config,\n",
        "            save_summaries_steps=None,\n",
        "            save_checkpoint_secs=None,\n",
        "            hooks=[log]\n",
        "    ) as sess:\n",
        "        try:\n",
        "            while not sess.should_stop():\n",
        "                sess.run(train, feed_dict={\n",
        "                            n_samples_: n_samples,\n",
        "                            # tf.keras.backend.learning_phase(): 1\n",
        "                         })\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            print('Input queues have been exhausted!')\n",
        "            pass\n",
        "\n",
        "        # Prediction, the [[None]] is to stop the default placeholder queue\n",
        "        # we keep learning phase flag on even in prediction phase to draw\n",
        "        # samples from predictive distribution\n",
        "        Ey = sess.run(phi,\n",
        "                      feed_dict={X_: Xq, Y_: [[None]], n_samples_: p_samples})\n",
        "\n",
        "        logPY = sess.run(logprob,\n",
        "                         feed_dict={Y_: Yi, X_: Xi, n_samples_: p_samples})\n",
        "\n",
        "    Eymean = Ey.mean(axis=0)  # Average samples to get mean predicted funtion\n",
        "    Py = np.exp(logPY.reshape(Ns, Ns))  # Turn log-prob into prob\n",
        "\n",
        "    # Plot\n",
        "    im_min = np.amin(Py)\n",
        "    im_size = np.amax(Py) - im_min\n",
        "    img = (Py - im_min) / im_size\n",
        "    f = bk.figure(tools='pan,box_zoom,reset', sizing_mode='stretch_both')\n",
        "    f.image(image=[img], x=-20., y=-4., dw=40., dh=8,\n",
        "            palette=bp.Plasma256)\n",
        "    f.circle(Xr.flatten(), Yr.flatten(), fill_color='blue', legend='Training')\n",
        "    f.line(Xs.flatten(), Ys.flatten(), line_color='blue', legend='Truth')\n",
        "    for y in Ey:\n",
        "        f.line(Xq.flatten(), y.flatten(), line_color='red', legend='Samples',\n",
        "               alpha=0.2)\n",
        "    f.line(Xq.flatten(), Eymean.flatten(), line_color='green', legend='Mean')\n",
        "    bk.show(f)\n",
        "    bk.save(f,filename=\"plot.html\")\n",
        "    bk.show(f)\n",
        "\n",
        "\n",
        "def batch_training(X, Y, batch_size, n_epochs):\n",
        "    \"\"\"Batch training queue convenience function.\"\"\"\n",
        "    data_tr = tf.data.Dataset.from_tensor_slices({'X': X, 'Y': Y}) \\\n",
        "        .shuffle(buffer_size=1000, seed=RSEED) \\\n",
        "        .repeat(n_epochs) \\\n",
        "        .batch(batch_size)\n",
        "    data = data_tr.make_one_shot_iterator().get_next()\n",
        "    return data['X'], data['Y']\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aboleth in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from aboleth) (1.3.3)\n",
            "Requirement already satisfied: tensorflow-probability>=0.3 in /usr/local/lib/python3.6/dist-packages (from aboleth) (0.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from aboleth) (1.12.0)\n",
            "Requirement already satisfied: tensorflow>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from aboleth) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.18.1->aboleth) (1.17.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.3->aboleth) (4.4.1)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.3->aboleth) (1.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.11.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.15.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.1.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.8.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.0->aboleth) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.10.0->aboleth) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.10.0->aboleth) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.10.0->aboleth) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.10.0->aboleth) (2.8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aboleth/distributions.py:157: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "Iterations = 50000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-1-267afee94ee7>:181: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aboleth/layers.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aboleth/util.py:169: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-1-267afee94ee7>:112: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:loss = 2.127343, step = 1\n",
            "INFO:tensorflow:loss = 0.722933, step = 1001 (1.279 sec)\n",
            "INFO:tensorflow:loss = 0.5190154, step = 2001 (1.218 sec)\n",
            "INFO:tensorflow:loss = 0.27492082, step = 3001 (1.215 sec)\n",
            "INFO:tensorflow:loss = 0.15118621, step = 4001 (1.188 sec)\n",
            "INFO:tensorflow:loss = -0.036333933, step = 5001 (1.221 sec)\n",
            "INFO:tensorflow:loss = 0.036029473, step = 6001 (1.190 sec)\n",
            "INFO:tensorflow:loss = 0.06290697, step = 7001 (1.209 sec)\n",
            "INFO:tensorflow:loss = -0.23616223, step = 8001 (1.189 sec)\n",
            "INFO:tensorflow:loss = 0.0062443255, step = 9001 (1.187 sec)\n",
            "INFO:tensorflow:loss = 0.07704635, step = 10001 (1.202 sec)\n",
            "INFO:tensorflow:loss = 0.16241544, step = 11001 (1.200 sec)\n",
            "INFO:tensorflow:loss = -0.1432812, step = 12001 (1.181 sec)\n",
            "INFO:tensorflow:loss = -0.20210531, step = 13001 (1.218 sec)\n",
            "INFO:tensorflow:loss = -0.09859126, step = 14001 (1.211 sec)\n",
            "INFO:tensorflow:loss = -0.061602104, step = 15001 (1.212 sec)\n",
            "INFO:tensorflow:loss = -0.31168202, step = 16001 (1.270 sec)\n",
            "INFO:tensorflow:loss = 0.09841734, step = 17001 (1.225 sec)\n",
            "INFO:tensorflow:loss = 0.106188126, step = 18001 (1.230 sec)\n",
            "INFO:tensorflow:loss = 0.04402733, step = 19001 (1.304 sec)\n",
            "INFO:tensorflow:loss = -0.12201906, step = 20001 (1.206 sec)\n",
            "INFO:tensorflow:loss = -0.10610761, step = 21001 (1.204 sec)\n",
            "INFO:tensorflow:loss = -0.08252766, step = 22001 (1.211 sec)\n",
            "INFO:tensorflow:loss = 0.104192495, step = 23001 (1.201 sec)\n",
            "INFO:tensorflow:loss = -0.18434036, step = 24001 (1.198 sec)\n",
            "INFO:tensorflow:loss = -0.052019805, step = 25001 (1.239 sec)\n",
            "INFO:tensorflow:loss = -0.15136461, step = 26001 (1.236 sec)\n",
            "INFO:tensorflow:loss = -0.18875273, step = 27001 (1.210 sec)\n",
            "INFO:tensorflow:loss = -0.39458457, step = 28001 (1.220 sec)\n",
            "INFO:tensorflow:loss = 0.008063197, step = 29001 (1.200 sec)\n",
            "INFO:tensorflow:loss = -0.05315345, step = 30001 (1.218 sec)\n",
            "INFO:tensorflow:loss = -0.26526988, step = 31001 (1.225 sec)\n",
            "INFO:tensorflow:loss = -0.1571663, step = 32001 (1.162 sec)\n",
            "INFO:tensorflow:loss = -0.2892057, step = 33001 (1.192 sec)\n",
            "INFO:tensorflow:loss = -0.18581204, step = 34001 (1.215 sec)\n",
            "INFO:tensorflow:loss = -0.21566369, step = 35001 (1.210 sec)\n",
            "INFO:tensorflow:loss = -0.21951884, step = 36001 (1.179 sec)\n",
            "INFO:tensorflow:loss = -0.19104235, step = 37001 (1.183 sec)\n",
            "INFO:tensorflow:loss = 0.038322274, step = 38001 (1.234 sec)\n",
            "INFO:tensorflow:loss = -0.30238688, step = 39001 (1.191 sec)\n",
            "INFO:tensorflow:loss = -0.15380804, step = 40001 (1.204 sec)\n",
            "INFO:tensorflow:loss = -0.16660246, step = 41001 (1.249 sec)\n",
            "INFO:tensorflow:loss = -0.22494744, step = 42001 (1.214 sec)\n",
            "INFO:tensorflow:loss = -0.06481382, step = 43001 (1.192 sec)\n",
            "INFO:tensorflow:loss = -0.12900136, step = 44001 (1.290 sec)\n",
            "INFO:tensorflow:loss = -0.19862118, step = 45001 (1.135 sec)\n",
            "INFO:tensorflow:loss = -0.14032601, step = 46001 (1.215 sec)\n",
            "INFO:tensorflow:loss = -0.32546237, step = 47001 (1.194 sec)\n",
            "INFO:tensorflow:loss = -0.21302803, step = 48001 (1.222 sec)\n",
            "INFO:tensorflow:loss = -0.047834147, step = 49001 (1.220 sec)\n",
            "Input queues have been exhausted!\n",
            "INFO:tensorflow:loss = nan, step = 50000 (1.292 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bokeh/io/saving.py:126: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
            "  warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
            "/usr/local/lib/python3.6/dist-packages/bokeh/io/saving.py:139: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
            "  warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}